import torch
from torch import nn
from model.utils import MaskedAttention


# ============================================================
# ðŸ§© GRU cÆ¡ báº£n (Diagnosis-only)
# ============================================================
class GRU(nn.Module):
    def __init__(self, code_num, hidden_dim, max_len, device=None):
        super().__init__()
        self.hidden_dim = hidden_dim
        self.max_len = max_len
        self.device = device

        self.gru_cell = nn.GRUCell(input_size=code_num, hidden_size=hidden_dim)
        self.hidden2codes = nn.Sequential(
            nn.Linear(hidden_dim, code_num),
            nn.Sigmoid()
        )

    def step(self, x, h=None):
        h_n = self.gru_cell(x, h)
        codes = self.hidden2codes(h_n)
        return codes, h_n

    def forward(self, noise):
        codes = self.hidden2codes(noise)
        h = torch.zeros(len(codes), self.hidden_dim, device=self.device)
        samples, hiddens = [], []
        for _ in range(self.max_len):
            samples.append(codes)
            codes, h = self.step(codes, h)
            hiddens.append(h)
        samples = torch.stack(samples, dim=1)
        hiddens = torch.stack(hiddens, dim=1)
        return samples, hiddens


# ============================================================
# ðŸ©º Dual-Stream GRU (Diagnosis + Procedure)
# ============================================================
class DualGRUGenerator(nn.Module):
    """
    Generate diagnosis & procedure sequences simultaneously.
    Two independent GRU decoders (shared latent).
    """
    def __init__(self, code_num_diag, code_num_proc, hidden_dim, max_len, device=None):
        super().__init__()
        self.device = device
        self.hidden_dim = hidden_dim
        self.max_len = max_len

        # Two GRU decoders
        self.gru_diag = GRU(code_num_diag, hidden_dim, max_len, device)
        self.gru_proc = GRU(code_num_proc, hidden_dim, max_len, device)

        # Optionally project same latent into two spaces
        self.fc_diag = nn.Linear(hidden_dim, hidden_dim)
        self.fc_proc = nn.Linear(hidden_dim, hidden_dim)

    def forward(self, z):
        """
        z: latent noise [batch, hidden_dim]
        Return: (samples_diag, samples_proc)
        """
        z_diag = self.fc_diag(z)
        z_proc = self.fc_proc(z)

        samples_diag, h_diag = self.gru_diag(z_diag)
        samples_proc, h_proc = self.gru_proc(z_proc)
        return samples_diag, samples_proc, h_diag, h_proc


# ============================================================
# ðŸŽ¯ Optional: smooth conditioning (fixed)
# ============================================================
class SmoothCondition(nn.Module):
    def __init__(self, code_num, attention_dim):
        super().__init__()
        self.attention = MaskedAttention(code_num, attention_dim)

    def forward(self, x, lens, target_codes):
        """
        x: [B, T, C]
        lens: [B]
        target_codes: 
          - [B] (chá»‰ sá»‘ code),
          - hoáº·c [B, C] (one-hot / logits),
          - hoáº·c list[tensor], má»—i pháº§n tá»­ cÃ³ thá»ƒ lÃ  scalar hoáº·c vector.
        """
        device = x.device
        B, T, C = x.shape

        # 1) attention score [B, T]
        score = self.attention(x, lens)

        # 2) Chuáº©n hoÃ¡ target_codes -> tensor chá»‰ sá»‘ [B] trÃªn Ä‘Ãºng device
        if isinstance(target_codes, torch.Tensor):
            # Náº¿u lÃ  phÃ¢n phá»‘i/one-hot: chiá»u cuá»‘i == C -> argmax theo chiá»u cuá»‘i
            if target_codes.ndim >= 1 and target_codes.shape[-1] == C:
                target_codes = target_codes.argmax(dim=-1)
            # CÃ²n láº¡i: Ã©p pháº³ng vá» (B,)
            if target_codes.ndim > 1:
                target_codes = target_codes.view(-1)
            target_codes = target_codes.to(device=device, dtype=torch.long)

        elif isinstance(target_codes, (list, tuple)):
            flat_idxs = []
            for t in target_codes:
                if isinstance(t, torch.Tensor):
                    tt = t.detach()
                    # náº¿u lÃ  phÃ¢n phá»‘i/one-hot theo chiá»u cuá»‘i
                    if tt.ndim >= 1 and tt.shape[-1] == C:
                        idx = int(tt.argmax(dim=-1).view(-1)[0].item())
                    else:
                        # khÃ´ng cháº¯c: láº¥y argmax cá»§a vector pháº³ng
                        if tt.numel() == 1:
                            idx = int(tt.item())
                        else:
                            idx = int(tt.view(-1).argmax().item())
                else:
                    idx = int(t)
                flat_idxs.append(idx)
            target_codes = torch.tensor(flat_idxs, dtype=torch.long, device=device)

        else:
            # scalar duy nháº¥t
            target_codes = torch.tensor([int(target_codes)], dtype=torch.long, device=device)

        # Ä‘áº£m báº£o Ä‘Ãºng kÃ­ch thÆ°á»›c B (náº¿u cáº§n, láº·p láº¡i)
        if target_codes.numel() != B:
            if target_codes.numel() == 1:
                target_codes = target_codes.expand(B)
            else:
                # fallback: cáº¯t hoáº·c tile cho khá»›p B
                if target_codes.numel() > B:
                    target_codes = target_codes.view(-1)[:B]
                else:
                    reps = (B + target_codes.numel() - 1) // target_codes.numel()
                    target_codes = target_codes.repeat(reps)[:B]

        target_codes = target_codes.clamp_(0, C - 1)

        # 3) scatter score vÃ o Ä‘Ãºng cá»™t code má»¥c tiÃªu
        score_tensor = torch.zeros(B, T, C, device=device, dtype=x.dtype)
        idx = target_codes.view(B, 1, 1).expand(B, T, 1)      # [B,T,1]
        score_tensor.scatter_(2, idx, score.unsqueeze(-1))    # [B,T,1]

        # 4) cá»™ng vÃ  clip
        x = torch.clamp(x + score_tensor, max=1)
        return x
